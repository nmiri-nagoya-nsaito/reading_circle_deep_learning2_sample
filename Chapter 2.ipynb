{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## カウントベースの手法\n",
    " ### Pythonによる下準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "\n",
    "text = text.lower()\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split(' ')\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['you',\n",
       " ' ',\n",
       " 'say',\n",
       " ' ',\n",
       " 'goodbye',\n",
       " ' ',\n",
       " 'and',\n",
       " ' ',\n",
       " 'i',\n",
       " ' ',\n",
       " 'say',\n",
       " ' ',\n",
       " 'hello',\n",
       " '.',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re.split('(\\W+)?', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 3, 'goodbye': 2, 'hello.': 5, 'i': 4, 'say': 1, 'you': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)\n",
    "print(word_to_id)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語の分散表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語の分散仮説"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共起行列(co-occurence matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "# 語彙数が全部で7個であることがわかる\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C[0] = [0 1 0 0 0 0 0]\n",
      "C[word_to_id['goodbye']] = [0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 単語の頻度を数える\n",
    "# コンテキストに含まれる単語の数を数え，表の形式にまとめる．これが共起行列\n",
    "C = np.array([\n",
    "    [0,1,0,0,0,0,0],\n",
    "    [1,0,1,0,1,1,0],\n",
    "    [0,1,0,1,0,0,0],\n",
    "    [0,0,1,0,1,0,0],\n",
    "    [0,1,0,1,0,0,0],\n",
    "    [0,1,0,0,0,0,1],\n",
    "    [0,0,0,0,0,1,0],\n",
    "], dtype=np.int32)\n",
    "\n",
    "# 単語1のベクトル\n",
    "print(\"C[0] = {c0}\".format(c0=C[0]))\n",
    "\n",
    "# 'goodbye' のベクトル\n",
    "print(\"C[word_to_id['goodbye']] = {c}\".format(c=C[word_to_id['goodbye']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共起行列の生成を自動化したい\n",
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    '''共起行列の作成\n",
    "\n",
    "    :param corpus: コーパス（単語IDのリスト）\n",
    "    :param vocab_size:語彙数\n",
    "    :param window_size:ウィンドウサイズ（ウィンドウサイズが1のときは、単語の左右1単語がコンテキスト）\n",
    "    :return: 共起行列\n",
    "    '''\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベクトル間の類似度\n",
    "いくつかの方法\n",
    "* ベクトルの内積\n",
    "* ユークリッド距離\n",
    "* コサイン類似度(cosine similarity)\n",
    "    * 同じ向きならば1，反対ならば-1となる\n",
    "\n",
    "$$\n",
    "similarity(x,y) = \\frac{x \\cdot y}{||x|| ||y||}\n",
    "= \\frac{x_1y_1+...+x_ny_n}{\\sqrt{x^2_1+...+x^2_n}\\sqrt{y^2_1+...+y^2_n}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067691154799\n"
     ]
    }
   ],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    '''コサイン類似度の算出\n",
    "\n",
    "    :param x: ベクトル\n",
    "    :param y: ベクトル\n",
    "    :param eps: ”0割り”防止のための微小値\n",
    "    :return:\n",
    "    '''\n",
    "    nx = x / (np.sqrt(np.sum(x ** 2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y ** 2)) + eps)\n",
    "    return np.dot(nx, ny)\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 類似単語のランキング表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    '''類似単語の検索\n",
    "\n",
    "    :param query: クエリ（テキスト）\n",
    "    :param word_to_id: 単語から単語IDへのディクショナリ\n",
    "    :param id_to_word: 単語IDから単語へのディクショナリ\n",
    "    :param word_matrix: 単語ベクトルをまとめた行列。各行に対応する単語のベクトルが格納されていることを想定する\n",
    "    :param top: 上位何位まで表示するか\n",
    "    '''\n",
    "    if query not in word_to_id:\n",
    "        print('%s is not found' % query)\n",
    "        return\n",
    "\n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "\n",
    "    vocab_size = len(id_to_word)\n",
    "\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return\n",
    "\n",
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カウントベース手法の改善\n",
    "### 相互情報量\n",
    "* 共起行列の要素の値（カウント数）はあまり良い性質を持たない\n",
    "    * 高頻度単語が常に関連性の高いワードとして挙げられてしまう\n",
    "\n",
    "相互情報量の定義\n",
    "\n",
    "$$\n",
    "PMI(x,y) = \\log_2{\\frac{P(x,y)}{P(x)P(y)}}\n",
    "= \\log_2{\\frac{\\frac{C(x,y)}{N}}{\\frac{C(x)}{N}\\frac{C(y)}{N}}}\n",
    "= \\log_2{\\frac{C(x,y)\\cdot N}{C(x)C(y)}}\n",
    "$$\n",
    "ここで\n",
    "* N: ワード数\n",
    "* C(x) : xの出現回数\n",
    "* C(x,y): xとyの共起回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps = 1e-8):\n",
    "    '''PPMI（正の相互情報量）の作成\n",
    "\n",
    "    :param C: 共起行列\n",
    "    :param verbose: 進行状況を出力するかどうか    \n",
    "    :return:\n",
    "    '''\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.1f%% done' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix = \n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI = \n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "W = ppmi(C)\n",
    "\n",
    "# 共起行列をPPMI行列に変換する\n",
    "np.set_printoptions(precision=3)\n",
    "print('covariance matrix = \\n{c}'.format(c=C))\n",
    "print('-'*50)\n",
    "print('PPMI = \\n{w}'.format(w=W))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元削減\n",
    "* PPMI 行列の問題点\n",
    "    * ほとんどの要素が0である．これは各要素の重要度が低いことを意味する\n",
    "    * そのようなベクトルはノイズに弱く，頑健性に乏しい\n",
    "* 次元削減とは\n",
    "    * ベクトルを，重要な情報を残しつつ，次元を削減すること\n",
    "    * データの分布をみて重要な軸を見つけることを行い，次元を削減する\n",
    "    * 次元削減したベクトルは0の要素が少ない，密な行列となる．これが望ましい分散表現である\n",
    "* 次元削減の方法：特異値分解(Singular Value Decomposition: SVD)\n",
    "$$\n",
    "X = USV^T\n",
    "$$\n",
    "ここで\n",
    "* U,V : 直交行列．列ベクトルは互いに直交\n",
    "* S : 対角行列．対角成分以外はすべて0\n",
    "\n",
    "それぞれの行列の特徴\n",
    "* U はなんらかの空間の軸（基底）を形成する．この行列を単語空間として扱うことができる\n",
    "* S の対角成分には「特異値」，つまり対応する軸の重要度が大きい順に並んでいる\n",
    "    * そこで，重要でない軸を削除することで次元を削減することができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.409e-01 -1.110e-16 -3.886e-16 -1.205e-01 -9.323e-01  0.000e+00\n",
      "   1.958e-17]\n",
      " [ 0.000e+00 -5.976e-01  1.802e-01  0.000e+00  0.000e+00 -7.812e-01\n",
      "   0.000e+00]\n",
      " [ 4.363e-01 -5.551e-17 -2.220e-16 -5.088e-01  2.253e-01 -1.388e-17\n",
      "  -7.071e-01]\n",
      " [ 1.110e-16 -4.978e-01  6.804e-01  2.776e-17 -1.110e-16  5.378e-01\n",
      "   9.555e-17]\n",
      " [ 4.363e-01 -3.124e-17 -1.600e-16 -5.088e-01  2.253e-01 -1.302e-17\n",
      "   7.071e-01]\n",
      " [ 7.092e-01 -3.124e-17 -1.600e-16  6.839e-01  1.710e-01 -1.302e-17\n",
      "   1.342e-16]\n",
      " [-1.943e-16 -6.285e-01 -7.103e-01 -2.776e-17  3.331e-16  3.169e-01\n",
      "  -1.230e-16]]\n",
      "[ 3.168  3.168  2.703  2.703  1.514  1.514 -0.   ]\n",
      "[[-0.000e+00  5.976e-01  1.110e-16  4.978e-01  2.776e-16 -2.776e-16\n",
      "   6.285e-01]\n",
      " [-3.409e-01 -2.220e-16 -4.363e-01  0.000e+00 -4.363e-01 -7.092e-01\n",
      "   0.000e+00]\n",
      " [ 1.205e-01 -5.551e-16  5.088e-01  0.000e+00  5.088e-01 -6.839e-01\n",
      "   0.000e+00]\n",
      " [ 0.000e+00 -1.802e-01 -1.527e-16 -6.804e-01  1.388e-17  8.327e-17\n",
      "   7.103e-01]\n",
      " [ 0.000e+00 -7.812e-01 -1.665e-16  5.378e-01 -1.110e-16  3.331e-16\n",
      "   3.169e-01]\n",
      " [-9.323e-01 -5.551e-17  2.253e-01  0.000e+00  2.253e-01  1.710e-01\n",
      "   0.000e+00]\n",
      " [ 0.000e+00  1.517e-16 -7.071e-01 -8.327e-17  7.071e-01  7.897e-17\n",
      "  -4.857e-17]]\n"
     ]
    }
   ],
   "source": [
    "# 特異値分解を行う\n",
    "U, S, V = np.linalg.svd(W)\n",
    "\n",
    "print(U)\n",
    "print(S)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.409e-01 -1.110e-16]\n",
      " [ 0.000e+00 -5.976e-01]\n",
      " [ 4.363e-01 -5.551e-17]\n",
      " [ 1.110e-16 -4.978e-01]\n",
      " [ 4.363e-01 -3.124e-17]\n",
      " [ 7.092e-01 -3.124e-17]\n",
      " [-1.943e-16 -6.285e-01]]\n"
     ]
    }
   ],
   "source": [
    "# U を次元削減するとしたら，先頭の2列を取り出すようなスライスによって表現する\n",
    "print(U[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109d8c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "\n",
    "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTBデータセット\n",
    "もう少し規模の大きいコーパスとしてPenn Treebank と呼ばれるコーパスを使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_size 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id[\"car\"]: 3856\n",
      "word_to_id[\"happy\"]: 4428\n",
      "word_to_id[\"lexus\"]: 7426\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('book_sample')\n",
    "from dataset import ptb\n",
    "\n",
    "corpus_ptb, word_to_id_ptb, id_to_word_ptb = ptb.load_data('train')\n",
    "\n",
    "print('corpus_size', len(corpus_ptb))\n",
    "print('corpus[:30]:',corpus_ptb[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word_ptb[0])\n",
    "print('id_to_word[1]:', id_to_word_ptb[1])\n",
    "print('id_to_word[2]:', id_to_word_ptb[2])\n",
    "print()\n",
    "print('word_to_id[\"car\"]:', word_to_id_ptb['car'])\n",
    "print('word_to_id[\"happy\"]:', word_to_id_ptb['happy'])\n",
    "print('word_to_id[\"lexus\"]:', word_to_id_ptb['lexus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting co-occurrence ...\n",
      "calculating PPMI ...\n",
      "1.0% done\n",
      "2.0% done\n",
      "3.0% done\n",
      "4.0% done\n",
      "5.0% done\n",
      "6.0% done\n",
      "7.0% done\n",
      "8.0% done\n",
      "9.0% done\n",
      "10.0% done\n",
      "11.0% done\n",
      "12.0% done\n",
      "13.0% done\n",
      "14.0% done\n",
      "15.0% done\n",
      "16.0% done\n",
      "17.0% done\n",
      "18.0% done\n",
      "19.0% done\n",
      "20.0% done\n",
      "21.0% done\n",
      "22.0% done\n",
      "23.0% done\n",
      "24.0% done\n",
      "25.0% done\n",
      "26.0% done\n",
      "27.0% done\n",
      "28.0% done\n",
      "29.0% done\n",
      "30.0% done\n",
      "31.0% done\n",
      "32.0% done\n",
      "33.0% done\n",
      "34.0% done\n",
      "35.0% done\n",
      "36.0% done\n",
      "37.0% done\n",
      "38.0% done\n",
      "39.0% done\n",
      "40.0% done\n",
      "41.0% done\n",
      "42.0% done\n",
      "43.0% done\n",
      "44.0% done\n",
      "45.0% done\n",
      "46.0% done\n",
      "47.0% done\n",
      "48.0% done\n",
      "49.0% done\n",
      "50.0% done\n",
      "51.0% done\n",
      "52.0% done\n",
      "53.0% done\n",
      "54.0% done\n",
      "55.0% done\n",
      "56.0% done\n",
      "57.0% done\n",
      "58.0% done\n",
      "59.0% done\n",
      "60.0% done\n",
      "61.0% done\n",
      "62.0% done\n",
      "63.0% done\n",
      "64.0% done\n",
      "65.0% done\n",
      "66.0% done\n",
      "67.0% done\n",
      "68.0% done\n",
      "69.0% done\n",
      "70.0% done\n",
      "71.0% done\n",
      "72.0% done\n",
      "73.0% done\n",
      "74.0% done\n",
      "75.0% done\n",
      "76.0% done\n",
      "77.0% done\n",
      "78.0% done\n",
      "79.0% done\n",
      "80.0% done\n",
      "81.0% done\n",
      "82.0% done\n",
      "83.0% done\n",
      "84.0% done\n",
      "85.0% done\n",
      "86.0% done\n",
      "87.0% done\n",
      "88.0% done\n",
      "89.0% done\n",
      "90.0% done\n",
      "91.0% done\n",
      "92.0% done\n",
      "93.0% done\n",
      "94.0% done\n",
      "95.0% done\n",
      "96.0% done\n",
      "97.0% done\n",
      "98.0% done\n",
      "99.0% done\n",
      "100.0% done\n",
      "calculating SVD ...\n",
      "\n",
      "[query] you\n",
      " empty: 3.6893488147419103e+19\n",
      " pete: 3.6893488147419103e+19\n",
      " r: 3.6893488147419103e+19\n",
      " banking: 3.6893488147419103e+19\n",
      " directors: 3.6893488147419103e+19\n",
      "\n",
      "[query] year\n",
      " repaid: 3.6893488147419103e+19\n",
      " a$: 3.6893488147419103e+19\n",
      " cosmetic: 3.6893488147419103e+19\n",
      " drew: 3.6893488147419103e+19\n",
      " literary: 3.6893488147419103e+19\n",
      "\n",
      "[query] car\n",
      " hurry: 3.6893488147419103e+19\n",
      " enforcement: 3.6893488147419103e+19\n",
      " viewers: 3.6893488147419103e+19\n",
      " mere: 3.6893488147419103e+19\n",
      " best: 3.6893488147419103e+19\n",
      "\n",
      "[query] toyota\n",
      " solution: 3.6893488147419103e+19\n",
      " dealers: 3.6893488147419103e+19\n",
      " curbing: 3.6893488147419103e+19\n",
      " japan: 3.6893488147419103e+19\n",
      " wires: 3.6893488147419103e+19\n"
     ]
    }
   ],
   "source": [
    "# PTBデータセットでの評価\n",
    "# ある単語を入力して，それに類似した単語の上位いくつかをPTBコーパスから取ってくる\n",
    "\n",
    "# このセルの実行の前提\n",
    "#     most_similar, create_to_matrix, ppmi が定義済みである\n",
    "#     PTB の load_data は実行済みである\n",
    "\n",
    "window_size_ptb = 2\n",
    "wordvec_size_ptb = 100\n",
    "\n",
    "vocab_size_ptb = len(word_to_id_ptb)\n",
    "\n",
    "print('counting co-occurrence ...')\n",
    "C = create_co_matrix(corpus_ptb, vocab_size_ptb, window_size_ptb)\n",
    "\n",
    "print('calculating PPMI ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "\n",
    "try:\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size_ptb, n_iter=5, random_state=None)\n",
    "except ImportError:\n",
    "    U, S, V = np.linglg.svd(W)\n",
    "\n",
    "word_vecs_ptb = U[:, :wordvec_size_ptb]\n",
    "\n",
    "queries = ['you','year','car','toyota']\n",
    "\n",
    "for query in queries:\n",
    "    most_similar(query, word_to_id_ptb, id_to_word_ptb, word_vecs_ptb, top=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
